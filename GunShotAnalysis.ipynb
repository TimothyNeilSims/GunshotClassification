{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timothy Sims\n",
    "## A Python notebooklassification of guns by their sound using machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLoading data and running LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 64, 100)           6000000   \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirecti  (None, 100)               60400     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6065705 (23.14 MB)\n",
      "Trainable params: 6065705 (23.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "2500/2500 [==============================] - 75s 29ms/step - loss: 0.6889 - accuracy: 0.7472 - val_loss: 0.5299 - val_accuracy: 0.8083\n",
      "Epoch 2/5\n",
      "2500/2500 [==============================] - 71s 28ms/step - loss: 0.4808 - accuracy: 0.8348 - val_loss: 0.5279 - val_accuracy: 0.8063\n",
      "Epoch 3/5\n",
      "2500/2500 [==============================] - 71s 29ms/step - loss: 0.3857 - accuracy: 0.8687 - val_loss: 0.5707 - val_accuracy: 0.8040\n",
      "Epoch 4/5\n",
      "2500/2500 [==============================] - 75s 30ms/step - loss: 0.3125 - accuracy: 0.8953 - val_loss: 0.6900 - val_accuracy: 0.7950\n",
      "Epoch 5/5\n",
      "2500/2500 [==============================] - 73s 29ms/step - loss: 0.2525 - accuracy: 0.9189 - val_loss: 0.7258 - val_accuracy: 0.7942\n",
      "922/922 [==============================] - 3s 3ms/step - loss: 0.7413 - accuracy: 0.7958\n",
      "Test Accuracy: 0.7958159446716309\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "\n",
    "train_data = pd.read_csv('train.csv')   # load data train and val\n",
    "val_data = pd.read_csv('val.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "train_data['cleaned_text'] = train_data['abstract_text'].str.lower()    # clean text\n",
    "val_data['cleaned_text'] = val_data['abstract_text'].str.lower()\n",
    "test_data['cleaned_text'] = test_data['abstract_text'].str.lower()\n",
    "\n",
    "vocab_size = 60000 \n",
    "max_length = 64\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)  # tokenize\n",
    "tokenizer.fit_on_texts(train_data['cleaned_text'])\n",
    "\n",
    "def get_sequences(tokenizer, data):\n",
    "    sequences = tokenizer.texts_to_sequences(data)\n",
    "    padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "    return padded\n",
    "\n",
    "train_sequences = get_sequences(tokenizer, train_data['cleaned_text'])  # convert to sequences and pad\n",
    "val_sequences = get_sequences(tokenizer, val_data['cleaned_text'])\n",
    "test_sequences = get_sequences(tokenizer, test_data['cleaned_text'])\n",
    "\n",
    "train_labels = pd.get_dummies(train_data['target']).values  # convert to one-hot\n",
    "val_labels = pd.get_dummies(val_data['target']).values\n",
    "test_labels = pd.get_dummies(test_data['target']).values\n",
    "\n",
    "model = tf.keras.Sequential([   # build model\n",
    "    tf.keras.layers.Embedding(vocab_size, 100, input_length=max_length),    # embedding layer\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50)),    # bidirectional LSTM layer\n",
    "    tf.keras.layers.Dropout(0.5),   # dropout layer\n",
    "    tf.keras.layers.Dense(50, activation='relu'),   # dense layer\n",
    "    tf.keras.layers.Dropout(0.5),   # dropout layer\n",
    "    tf.keras.layers.Dense(len(train_data['target'].unique()), activation='softmax') # output layer\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # compile model\n",
    "model.summary() # print model summary\n",
    "\n",
    "history = model.fit(train_sequences, train_labels, epochs=5, validation_data=(val_sequences, val_labels))   # train model\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_sequences, test_labels)   # evaluate model\n",
    "print(f\"Test Accuracy: {test_acc}\") # print test accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I changed the model to include two dropout layers and a dense layer with a size of 50\n",
    "# I also changed the embedding size to 100 and the LSTM layer to 50\n",
    "# Doing these along with changing the epoch to 5 allowed me to improve the accuracy by 2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining LSTM and CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM+CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2148, 128, 128, 1)\n",
      "Epoch 1/100\n",
      "54/54 [==============================] - 10s 137ms/step - loss: 1.2963 - accuracy: 0.3964 - val_loss: 1.3238 - val_accuracy: 0.3093\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 7s 131ms/step - loss: 1.0978 - accuracy: 0.5233 - val_loss: 1.2405 - val_accuracy: 0.4233\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 7s 134ms/step - loss: 0.9289 - accuracy: 0.6170 - val_loss: 1.2492 - val_accuracy: 0.4977\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 8s 140ms/step - loss: 0.6623 - accuracy: 0.7456 - val_loss: 1.0850 - val_accuracy: 0.5488\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 7s 138ms/step - loss: 0.4523 - accuracy: 0.8283 - val_loss: 1.0989 - val_accuracy: 0.5814\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 7s 133ms/step - loss: 0.3364 - accuracy: 0.8818 - val_loss: 0.8141 - val_accuracy: 0.6860\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 0.1741 - accuracy: 0.9424 - val_loss: 0.7071 - val_accuracy: 0.6977\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 7s 131ms/step - loss: 0.1293 - accuracy: 0.9546 - val_loss: 0.4410 - val_accuracy: 0.8233\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 7s 135ms/step - loss: 0.1263 - accuracy: 0.9546 - val_loss: 0.8751 - val_accuracy: 0.6884\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 7s 134ms/step - loss: 0.1123 - accuracy: 0.9616 - val_loss: 0.3443 - val_accuracy: 0.8814\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 7s 136ms/step - loss: 0.0664 - accuracy: 0.9773 - val_loss: 0.2976 - val_accuracy: 0.8884\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 7s 134ms/step - loss: 0.0629 - accuracy: 0.9814 - val_loss: 0.3093 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 7s 138ms/step - loss: 0.0550 - accuracy: 0.9872 - val_loss: 0.3038 - val_accuracy: 0.9093\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 7s 134ms/step - loss: 0.0253 - accuracy: 0.9948 - val_loss: 0.2085 - val_accuracy: 0.9302\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 7s 134ms/step - loss: 0.0224 - accuracy: 0.9919 - val_loss: 0.2438 - val_accuracy: 0.9372\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 7s 133ms/step - loss: 0.0326 - accuracy: 0.9901 - val_loss: 0.3242 - val_accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 7s 136ms/step - loss: 0.0380 - accuracy: 0.9849 - val_loss: 0.2208 - val_accuracy: 0.9326\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 7s 133ms/step - loss: 0.0286 - accuracy: 0.9924 - val_loss: 0.1832 - val_accuracy: 0.9488\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 7s 135ms/step - loss: 0.0413 - accuracy: 0.9843 - val_loss: 0.1828 - val_accuracy: 0.9395\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 7s 135ms/step - loss: 0.0467 - accuracy: 0.9843 - val_loss: 0.2299 - val_accuracy: 0.9349\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 7s 133ms/step - loss: 0.0351 - accuracy: 0.9878 - val_loss: 0.2881 - val_accuracy: 0.9209\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 7s 134ms/step - loss: 0.0266 - accuracy: 0.9924 - val_loss: 0.2170 - val_accuracy: 0.9419\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.2399 - val_accuracy: 0.9279\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 7s 134ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.3021 - val_accuracy: 0.9140\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 7s 134ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.2115 - val_accuracy: 0.9372\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 7s 132ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1717 - val_accuracy: 0.9488\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 7s 131ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.1510 - val_accuracy: 0.9535\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 7s 131ms/step - loss: 0.0423 - accuracy: 0.9860 - val_loss: 0.3492 - val_accuracy: 0.9070\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 7s 132ms/step - loss: 0.0398 - accuracy: 0.9913 - val_loss: 0.3260 - val_accuracy: 0.9163\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 7s 131ms/step - loss: 0.0279 - accuracy: 0.9913 - val_loss: 0.2196 - val_accuracy: 0.9465\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 7s 133ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.2416 - val_accuracy: 0.9372\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 0.0380 - accuracy: 0.9895 - val_loss: 0.2399 - val_accuracy: 0.9326\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 0.0132 - accuracy: 0.9948 - val_loss: 0.2230 - val_accuracy: 0.9349\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 0.0239 - accuracy: 0.9942 - val_loss: 0.1982 - val_accuracy: 0.9395\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.2746 - val_accuracy: 0.9302\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 0.0192 - accuracy: 0.9948 - val_loss: 0.2944 - val_accuracy: 0.9233\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.2199 - val_accuracy: 0.9535\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.2309 - val_accuracy: 0.9326\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.1790 - val_accuracy: 0.9535\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.1304 - val_accuracy: 0.9605\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 7s 128ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.1587 - val_accuracy: 0.9535\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9558\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 6.2575e-04 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9628\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.2538 - val_accuracy: 0.9372\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.1750 - val_accuracy: 0.9558\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 4.0032e-04 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9442\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 3.6637e-04 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9558\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 3.0630e-04 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9605\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 1.4351e-04 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9605\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 2.0487e-04 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9628\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 1.7080e-04 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9605\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 7s 128ms/step - loss: 2.1358e-04 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9628\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 1.0473e-04 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9628\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 1.1792e-04 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9628\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 7s 128ms/step - loss: 8.9616e-05 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9651\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 1.1256e-04 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9651\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 8.0558e-05 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 0.9674\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 8.8102e-05 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9651\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 7s 128ms/step - loss: 1.2001e-04 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9628\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 1.1081e-04 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9605\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 1.0083e-04 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9535\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 8.8206e-05 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9581\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 7s 131ms/step - loss: 1.6370e-04 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9651\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 7s 128ms/step - loss: 1.0182e-04 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9605\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.6225 - val_accuracy: 0.8419\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 0.2247 - accuracy: 0.9226 - val_loss: 0.4019 - val_accuracy: 0.8860\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 7s 131ms/step - loss: 0.0798 - accuracy: 0.9721 - val_loss: 0.2615 - val_accuracy: 0.9093\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 0.0543 - accuracy: 0.9820 - val_loss: 0.2695 - val_accuracy: 0.9163\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.2439 - val_accuracy: 0.9279\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.2903 - val_accuracy: 0.9140\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3228 - val_accuracy: 0.9233\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 0.2210 - val_accuracy: 0.9512\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 7s 128ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.2092 - val_accuracy: 0.9558\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 8.2697e-04 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9628\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 5.3779e-04 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9628\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 3.7901e-04 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9651\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 3.2789e-04 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9558\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 7s 128ms/step - loss: 2.5927e-04 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9651\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 2.9279e-04 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9628\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 1.9119e-04 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9605\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 2.3879e-04 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9605\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 1.7154e-04 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9628\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 1.7969e-04 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9605\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 1.7412e-04 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9628\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 7s 128ms/step - loss: 4.6877e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9605\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 1.7572e-04 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9605\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 1.6947e-04 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9628\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 1.6554e-04 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9651\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 7s 130ms/step - loss: 1.5968e-04 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9651\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 7s 131ms/step - loss: 1.3574e-04 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9651\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 1.0147e-04 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9651\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 1.6955e-04 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9605\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 7s 129ms/step - loss: 9.5576e-05 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9488\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 7s 131ms/step - loss: 9.3227e-05 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9535\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 7s 137ms/step - loss: 7.3584e-05 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9558\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 7s 132ms/step - loss: 1.0399e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9605\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 7s 134ms/step - loss: 4.7253e-05 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9581\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 7s 131ms/step - loss: 5.1850e-05 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9605\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 7s 134ms/step - loss: 6.4000e-05 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9674\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 7s 132ms/step - loss: 3.8769e-05 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9698\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2336 - accuracy: 0.9698\n",
      "Test Accuracy: 0.9697674512863159\n",
      "Test loss: 0.2336137741804123\n",
      "14/14 [==============================] - 1s 37ms/step\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "       38s&ws_dot38_caliber       0.98      0.99      0.99       102\n",
      "ruger_ar_556_dot223_caliber       0.98      0.97      0.97       120\n",
      "     remington_870_12_gauge       0.99      0.91      0.95        78\n",
      "       glock_17_9mm_caliber       0.94      0.99      0.97       130\n",
      "\n",
      "                   accuracy                           0.97       430\n",
      "                  macro avg       0.97      0.96      0.97       430\n",
      "               weighted avg       0.97      0.97      0.97       430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Bidirectional, LSTM, Reshape\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def read_data(folder_path, fft_size=1024, hop_length=None, win_length=None):    # added fft size hop length and win length as extra parameters\n",
    "    labels = []\n",
    "    spectrograms = []\n",
    "\n",
    "    for label in os.listdir(folder_path):\n",
    "        subfolder_path = os.path.join(folder_path, label)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            for file in os.listdir(subfolder_path):\n",
    "                file_path = os.path.join(subfolder_path, file)\n",
    "                if file_path.endswith('.wav'):\n",
    "                    y, sr = librosa.load(file_path)\n",
    "                    spectrogram = librosa.stft(y, n_fft=fft_size, hop_length=hop_length, win_length=win_length)\n",
    "                    spectrogram = np.abs(spectrogram)\n",
    "                    spectrograms.append(spectrogram)\n",
    "                    labels.append(label)\n",
    "\n",
    "    return spectrograms, labels\n",
    "\n",
    "def pad2d(a, desired_size):\n",
    "    rows, cols = a.shape\n",
    "    padded_a = np.zeros((desired_size, desired_size))\n",
    "    rows_to_copy = min(rows, desired_size)\n",
    "    cols_to_copy = min(cols, desired_size)\n",
    "    padded_a[:rows_to_copy, :cols_to_copy] = a[:rows_to_copy, :cols_to_copy]\n",
    "    return padded_a\n",
    "\n",
    "def create_lstm_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))   # conv2d 32 3x3\n",
    "    model.add(MaxPooling2D((2, 2))) # maxpool 2x2\n",
    "    model.add(BatchNormalization()) # batchnorm\n",
    "    model.add(Conv2D(64, (4, 4), activation='relu'))    # changed to 4x4\n",
    "    model.add(MaxPooling2D((2, 2))) # maxpool 2x2\n",
    "    model.add(BatchNormalization()) # batchnorm\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, (5, 5), activation='relu'))   # newly added conv2d 256 5x5\n",
    "    model.add(MaxPooling2D((2, 2))) # maxpool 2x2\n",
    "    model.add(BatchNormalization()) # batchnorm\n",
    "    model.add(Flatten())    # flatten the model\n",
    "\n",
    "    model.add(Reshape((80, 80)))    # reshape to 80x80 for lstm\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=False)))  # bidirectional lstm 64\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))    # dense 128 relu\n",
    "    model.add(Dropout(0.5)) # dropout 0.5\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax')) # dense for output\n",
    "    return model\n",
    "\n",
    "folder_path = 'Gun Shot dataset/edge-collected-gunshot-audio'\n",
    "\n",
    "spectrograms, labels = read_data(folder_path, fft_size=2048, hop_length=512, win_length=2048)   # added fft size hop length and win length as extra parameters\n",
    "\n",
    "\n",
    "desired_spectrogram_size = 128  \n",
    "spectrograms = np.array([pad2d(s, desired_spectrogram_size) for s in spectrograms])\n",
    "spectrograms = np.expand_dims(spectrograms, axis=-1) \n",
    "print(spectrograms.shape)\n",
    "label_dict = {label: i for i, label in enumerate(set(labels))}\n",
    "y = np.array([label_dict[label] for label in labels])\n",
    "y = to_categorical(y) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(spectrograms, y, test_size=0.2, random_state=42)\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "model = create_lstm_cnn_model(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
    "\n",
    "lstm_cnn_test_loss, lstm_cnn_test_accuracy = model.evaluate(X_test, y_test)  # evaluate model\n",
    "print(f\"Test Accuracy: {lstm_cnn_test_accuracy}\")   # print test accuracy\n",
    "print(f\"Test loss: {lstm_cnn_test_loss}\")   # print test loss\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "lstm_cnn_report = classification_report(y_true_classes, y_pred_classes, target_names=label_dict.keys())  # classification report to show precision, recall, and f1 score\n",
    "\n",
    "print(lstm_cnn_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing the LSTM part of the model was a bit challenging as I had to reshape the data to fit the LSTM layer\n",
    "# eventually using the output given from errors I was able to reshape the data and get the model to work\n",
    "# I had tried more LSTM layers like I had in the LSTM only model but had to remove them as they only hurt the accuracy of the model\n",
    "# I also tried different numbers of epochs before settling on 100, I tried lower numbers however the accuracy was not as good\n",
    "# thought the val accuracy drops often after some epochs, in the end it recovers and gives a good final accuracy\n",
    "\n",
    "# the accuracy in the end was .97 or 97% which is quite good\n",
    "# the model is most precise with the Remington 870 at 99% and least precise with the Glock 17 at 94%\n",
    "# this means that when the model predicts the Glock, it is 3% more likely to be wrong than when it predicts the Remington 870\n",
    "\n",
    "# the category with the highest recall is a tie between the 38 S&W and the Glock 17 with 99%, the lowest recall is the Remington 870 with 91%\n",
    "# this means that when the model predicts that it is NOT a Remington 870, it is 8% more likely to be wrong than when it predicts that it is NOT a 38 S&W or a Glock 17\n",
    "\n",
    "# The highest F1 score is the 38 S&W with 99%, the lowest is the Remington 870 with 95%\n",
    "# this means that overall the model is 4% more accurate when predicting the 38 S&W than when predicting the Remington 870\n",
    "# The performance of the model on the Remington 870 is the worst overall and in recall, but this is most likely because the Remington 870 has the fewest samples in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2148, 128, 128)\n",
      "Epoch 1/100\n",
      "54/54 [==============================] - 8s 83ms/step - loss: 1.3456 - accuracy: 0.3475 - val_loss: 1.2021 - val_accuracy: 0.4721\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 4s 70ms/step - loss: 1.1351 - accuracy: 0.5052 - val_loss: 1.0573 - val_accuracy: 0.5465\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.9764 - accuracy: 0.5908 - val_loss: 0.8719 - val_accuracy: 0.6233\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.8109 - accuracy: 0.6874 - val_loss: 1.0386 - val_accuracy: 0.6256\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 4s 71ms/step - loss: 0.6945 - accuracy: 0.7311 - val_loss: 0.7732 - val_accuracy: 0.6884\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 4s 70ms/step - loss: 0.6488 - accuracy: 0.7520 - val_loss: 0.7369 - val_accuracy: 0.7047\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 4s 71ms/step - loss: 0.5663 - accuracy: 0.7905 - val_loss: 0.5368 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.4767 - accuracy: 0.8289 - val_loss: 0.5708 - val_accuracy: 0.7814\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.4269 - accuracy: 0.8417 - val_loss: 0.6402 - val_accuracy: 0.7744\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.3816 - accuracy: 0.8452 - val_loss: 0.4551 - val_accuracy: 0.8372\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.4816 - accuracy: 0.8265 - val_loss: 0.4594 - val_accuracy: 0.8465\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.3477 - accuracy: 0.8714 - val_loss: 0.3721 - val_accuracy: 0.8674\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.3091 - accuracy: 0.8900 - val_loss: 0.4846 - val_accuracy: 0.8372\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 4s 77ms/step - loss: 0.2740 - accuracy: 0.8993 - val_loss: 0.3703 - val_accuracy: 0.8605\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.2621 - accuracy: 0.9057 - val_loss: 0.4338 - val_accuracy: 0.8628\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 4s 78ms/step - loss: 0.2331 - accuracy: 0.9139 - val_loss: 0.4958 - val_accuracy: 0.8209\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.2458 - accuracy: 0.9179 - val_loss: 0.3648 - val_accuracy: 0.8791\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.1851 - accuracy: 0.9354 - val_loss: 0.4042 - val_accuracy: 0.8698\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.3013 - accuracy: 0.8987 - val_loss: 0.3468 - val_accuracy: 0.8674\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.2419 - accuracy: 0.9127 - val_loss: 0.3852 - val_accuracy: 0.8767\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.1856 - accuracy: 0.9377 - val_loss: 0.3823 - val_accuracy: 0.8744\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 4s 78ms/step - loss: 0.1570 - accuracy: 0.9511 - val_loss: 0.3445 - val_accuracy: 0.8860\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 4s 79ms/step - loss: 0.1515 - accuracy: 0.9453 - val_loss: 0.5002 - val_accuracy: 0.8558\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 4s 77ms/step - loss: 0.2172 - accuracy: 0.9267 - val_loss: 0.4769 - val_accuracy: 0.8628\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.1957 - accuracy: 0.9319 - val_loss: 0.4394 - val_accuracy: 0.8698\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.2078 - accuracy: 0.9319 - val_loss: 0.3679 - val_accuracy: 0.8907\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.1213 - accuracy: 0.9645 - val_loss: 0.4046 - val_accuracy: 0.8930\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.1461 - accuracy: 0.9505 - val_loss: 0.4201 - val_accuracy: 0.8674\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.1291 - accuracy: 0.9633 - val_loss: 0.4921 - val_accuracy: 0.8651\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.1659 - accuracy: 0.9430 - val_loss: 0.4343 - val_accuracy: 0.8814\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.1768 - accuracy: 0.9412 - val_loss: 0.4430 - val_accuracy: 0.8721\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.1468 - accuracy: 0.9476 - val_loss: 0.3064 - val_accuracy: 0.9070\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.1182 - accuracy: 0.9552 - val_loss: 0.3921 - val_accuracy: 0.8860\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.1099 - accuracy: 0.9633 - val_loss: 0.3951 - val_accuracy: 0.9116\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0950 - accuracy: 0.9657 - val_loss: 0.3510 - val_accuracy: 0.8977\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 4s 76ms/step - loss: 0.0810 - accuracy: 0.9715 - val_loss: 0.3708 - val_accuracy: 0.9140\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.1903 - accuracy: 0.9354 - val_loss: 0.3760 - val_accuracy: 0.8814\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.1064 - accuracy: 0.9721 - val_loss: 0.4707 - val_accuracy: 0.8628\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0714 - accuracy: 0.9790 - val_loss: 0.4206 - val_accuracy: 0.8837\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 4s 76ms/step - loss: 0.0546 - accuracy: 0.9814 - val_loss: 0.3880 - val_accuracy: 0.9023\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0700 - accuracy: 0.9761 - val_loss: 0.4397 - val_accuracy: 0.8953\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.1365 - accuracy: 0.9563 - val_loss: 0.4210 - val_accuracy: 0.8977\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.1106 - accuracy: 0.9598 - val_loss: 0.4631 - val_accuracy: 0.8884\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 4s 76ms/step - loss: 0.0918 - accuracy: 0.9721 - val_loss: 0.3699 - val_accuracy: 0.9116\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0641 - accuracy: 0.9785 - val_loss: 0.3685 - val_accuracy: 0.8977\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.1291 - accuracy: 0.9593 - val_loss: 0.4201 - val_accuracy: 0.8791\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0874 - accuracy: 0.9703 - val_loss: 0.3888 - val_accuracy: 0.9093\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.0674 - accuracy: 0.9814 - val_loss: 0.3473 - val_accuracy: 0.9209\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0465 - accuracy: 0.9814 - val_loss: 0.3554 - val_accuracy: 0.9070\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0370 - accuracy: 0.9889 - val_loss: 0.2937 - val_accuracy: 0.9070\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0559 - accuracy: 0.9820 - val_loss: 0.3403 - val_accuracy: 0.9023\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.0643 - accuracy: 0.9779 - val_loss: 0.3692 - val_accuracy: 0.9116\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 4s 76ms/step - loss: 0.0492 - accuracy: 0.9849 - val_loss: 0.3662 - val_accuracy: 0.9140\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 4s 77ms/step - loss: 0.1134 - accuracy: 0.9668 - val_loss: 0.5005 - val_accuracy: 0.8791\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 4s 78ms/step - loss: 0.1445 - accuracy: 0.9546 - val_loss: 0.4584 - val_accuracy: 0.8721\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 4s 78ms/step - loss: 0.0609 - accuracy: 0.9820 - val_loss: 0.3211 - val_accuracy: 0.9279\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 4s 77ms/step - loss: 0.0766 - accuracy: 0.9721 - val_loss: 0.3544 - val_accuracy: 0.9116\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0540 - accuracy: 0.9814 - val_loss: 0.3710 - val_accuracy: 0.9186\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0906 - accuracy: 0.9767 - val_loss: 0.3711 - val_accuracy: 0.9070\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.0464 - accuracy: 0.9843 - val_loss: 0.3942 - val_accuracy: 0.9070\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0438 - accuracy: 0.9872 - val_loss: 0.3690 - val_accuracy: 0.9209\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0617 - accuracy: 0.9820 - val_loss: 0.4147 - val_accuracy: 0.9000\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 4s 76ms/step - loss: 0.0511 - accuracy: 0.9814 - val_loss: 0.3404 - val_accuracy: 0.9093\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.0690 - accuracy: 0.9802 - val_loss: 0.3137 - val_accuracy: 0.9233\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.0391 - accuracy: 0.9866 - val_loss: 0.4020 - val_accuracy: 0.9047\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 4s 76ms/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 0.3996 - val_accuracy: 0.9349\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0463 - accuracy: 0.9872 - val_loss: 0.4073 - val_accuracy: 0.9070\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 4s 76ms/step - loss: 0.0768 - accuracy: 0.9756 - val_loss: 0.4766 - val_accuracy: 0.8698\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 4s 76ms/step - loss: 0.1251 - accuracy: 0.9633 - val_loss: 0.4073 - val_accuracy: 0.9000\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 4s 77ms/step - loss: 0.0483 - accuracy: 0.9843 - val_loss: 0.4452 - val_accuracy: 0.9140\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 4s 76ms/step - loss: 0.0487 - accuracy: 0.9872 - val_loss: 0.4666 - val_accuracy: 0.8930\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 4s 77ms/step - loss: 0.0409 - accuracy: 0.9860 - val_loss: 0.4242 - val_accuracy: 0.9000\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 4s 77ms/step - loss: 0.0459 - accuracy: 0.9831 - val_loss: 0.3814 - val_accuracy: 0.9023\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 4s 81ms/step - loss: 0.0539 - accuracy: 0.9843 - val_loss: 0.3904 - val_accuracy: 0.9093\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0722 - accuracy: 0.9796 - val_loss: 0.3682 - val_accuracy: 0.9070\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 4s 74ms/step - loss: 0.0645 - accuracy: 0.9790 - val_loss: 0.3578 - val_accuracy: 0.9186\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0343 - accuracy: 0.9901 - val_loss: 0.4630 - val_accuracy: 0.8977\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0500 - accuracy: 0.9820 - val_loss: 0.4180 - val_accuracy: 0.9047\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0604 - accuracy: 0.9843 - val_loss: 0.3425 - val_accuracy: 0.9186\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0597 - accuracy: 0.9849 - val_loss: 0.3316 - val_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0488 - accuracy: 0.9866 - val_loss: 0.3279 - val_accuracy: 0.9209\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.3520 - val_accuracy: 0.9163\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0317 - accuracy: 0.9901 - val_loss: 0.3991 - val_accuracy: 0.9000\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0427 - accuracy: 0.9884 - val_loss: 0.3872 - val_accuracy: 0.9070\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0283 - accuracy: 0.9919 - val_loss: 0.3688 - val_accuracy: 0.9163\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0330 - accuracy: 0.9872 - val_loss: 0.4588 - val_accuracy: 0.9093\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0497 - accuracy: 0.9878 - val_loss: 0.5256 - val_accuracy: 0.9047\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 4s 73ms/step - loss: 0.0947 - accuracy: 0.9732 - val_loss: 0.4379 - val_accuracy: 0.9000\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 0.4682 - val_accuracy: 0.9116\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0389 - accuracy: 0.9872 - val_loss: 0.4019 - val_accuracy: 0.9070\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 4s 72ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.3587 - val_accuracy: 0.9233\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 4s 76ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.3167 - val_accuracy: 0.9326\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.0236 - accuracy: 0.9942 - val_loss: 0.3291 - val_accuracy: 0.9256\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 4s 78ms/step - loss: 0.0349 - accuracy: 0.9901 - val_loss: 0.4576 - val_accuracy: 0.9140\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 4s 76ms/step - loss: 0.0241 - accuracy: 0.9907 - val_loss: 0.4427 - val_accuracy: 0.9070\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 4s 79ms/step - loss: 0.0438 - accuracy: 0.9889 - val_loss: 0.5548 - val_accuracy: 0.8907\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 4s 77ms/step - loss: 0.0629 - accuracy: 0.9843 - val_loss: 0.4420 - val_accuracy: 0.9093\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 4s 77ms/step - loss: 0.0563 - accuracy: 0.9831 - val_loss: 0.4680 - val_accuracy: 0.9070\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 4s 77ms/step - loss: 0.0283 - accuracy: 0.9901 - val_loss: 0.4056 - val_accuracy: 0.9140\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 4s 78ms/step - loss: 0.0152 - accuracy: 0.9965 - val_loss: 0.3739 - val_accuracy: 0.9186\n",
      "14/14 [==============================] - 1s 16ms/step\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.3739 - accuracy: 0.9186\n",
      "Test Accuracy: 0.9186046719551086\n",
      "Test loss: 0.37390559911727905\n",
      "14/14 [==============================] - 0s 16ms/step\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "       38s&ws_dot38_caliber       0.88      0.98      0.93       102\n",
      "ruger_ar_556_dot223_caliber       0.94      0.93      0.93       120\n",
      "     remington_870_12_gauge       0.93      0.86      0.89        78\n",
      "       glock_17_9mm_caliber       0.92      0.90      0.91       130\n",
      "\n",
      "                   accuracy                           0.92       430\n",
      "                  macro avg       0.92      0.92      0.92       430\n",
      "               weighted avg       0.92      0.92      0.92       430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Bidirectional, LSTM, Reshape\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def read_data(folder_path, fft_size=1024, hop_length=None, win_length=None):\n",
    "    labels = []\n",
    "    spectrograms = []\n",
    "\n",
    "    for label in os.listdir(folder_path):\n",
    "        subfolder_path = os.path.join(folder_path, label)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            for file in os.listdir(subfolder_path):\n",
    "                file_path = os.path.join(subfolder_path, file)\n",
    "                if file_path.endswith('.wav'):\n",
    "                    y, sr = librosa.load(file_path)\n",
    "                    spectrogram = librosa.stft(y, n_fft=fft_size, hop_length=hop_length, win_length=win_length)\n",
    "                    spectrogram = np.abs(spectrogram)\n",
    "                    spectrograms.append(spectrogram)\n",
    "                    labels.append(label)\n",
    "\n",
    "    return spectrograms, labels\n",
    "\n",
    "def pad2d(a, desired_size):\n",
    "    rows, cols = a.shape\n",
    "    padded_a = np.zeros((desired_size, desired_size))\n",
    "    rows_to_copy = min(rows, desired_size)\n",
    "    cols_to_copy = min(cols, desired_size)\n",
    "    padded_a[:rows_to_copy, :cols_to_copy] = a[:rows_to_copy, :cols_to_copy]\n",
    "    return padded_a\n",
    "\n",
    "def create_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape))  # bidirectional lstm 64\n",
    "    model.add(Dropout(0.5)) # dropout 0.5\n",
    "\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=False)))  # bidirectional lstm 64\n",
    "    model.add(Dropout(0.5)) # dropout 0.5\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))    # dense 128\n",
    "    model.add(Dropout(0.5)) # dropout 0.5\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax')) # dense for output\n",
    "\n",
    "    return model\n",
    "\n",
    "folder_path = 'Gun Shot dataset/edge-collected-gunshot-audio'\n",
    "\n",
    "spectrograms, labels = read_data(folder_path, fft_size=2048, hop_length=512, win_length=2048)\n",
    "\n",
    "\n",
    "desired_spectrogram_size = 128  \n",
    "spectrograms = np.array([pad2d(s, desired_spectrogram_size) for s in spectrograms]) # pad\n",
    "spectrograms = np.expand_dims(spectrograms, axis=-1)    # expand dims\n",
    "spectrograms = spectrograms.reshape(spectrograms.shape[0], desired_spectrogram_size, -1)    # reshape\n",
    "print(spectrograms.shape)   # print shape\n",
    "label_dict = {label: i for i, label in enumerate(set(labels))}  # create label dict\n",
    "y = np.array([label_dict[label] for label in labels])\n",
    "y = to_categorical(y)  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(spectrograms, y, test_size=0.2, random_state=42)    # train test split\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "model = create_lstm_model(input_shape, num_classes) # create model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # compile model\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))   # train model\n",
    "\n",
    "y_pred = model.predict(X_test)  # predict\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # get classes\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "lstm_test_loss, lstm_test_accuracy = model.evaluate(X_test, y_test) # evaluate model\n",
    "print(f\"Test Accuracy: {lstm_test_accuracy}\")   # print test accuracy\n",
    "print(f\"Test loss: {lstm_test_loss}\")   # print test loss\n",
    "\n",
    "y_pred = model.predict(X_test)  # predict\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "lstm_report = classification_report(y_true_classes, y_pred_classes, target_names=label_dict.keys()) # classification report to show precision, recall, and f1 score\n",
    "\n",
    "print(lstm_report)  # print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LSTM model was slightly more accurate than the provided CNN model, with an accuracy of 92% compared to 90%\n",
    "# however it was difficult to improve it further, and ultimately needed to be combined with the CNN model to get the best results\n",
    "# In the individual LSTM model I had more layers of LSTM and dropout compared to the combined model\n",
    "# these were removed from the combined model as they were not helping, after removing them the accuracy increased to 97% where it stayed\n",
    "\n",
    "# The LSTM model alone is not sufficient for this task as CNN or the combined model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2148, 128, 128, 1)\n",
      "Epoch 1/100\n",
      "54/54 [==============================] - 7s 107ms/step - loss: 2.4161 - accuracy: 0.3696 - val_loss: 2.8922 - val_accuracy: 0.3860\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 1.4986 - accuracy: 0.4529 - val_loss: 1.6074 - val_accuracy: 0.3512\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 6s 107ms/step - loss: 1.3690 - accuracy: 0.4534 - val_loss: 1.2929 - val_accuracy: 0.4372\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 6s 112ms/step - loss: 1.2685 - accuracy: 0.5169 - val_loss: 1.2785 - val_accuracy: 0.4907\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 6s 106ms/step - loss: 1.1705 - accuracy: 0.5215 - val_loss: 1.1517 - val_accuracy: 0.5070\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 1.1247 - accuracy: 0.5512 - val_loss: 1.0685 - val_accuracy: 0.5814\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.9496 - accuracy: 0.5821 - val_loss: 1.0961 - val_accuracy: 0.5093\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 6s 108ms/step - loss: 0.8956 - accuracy: 0.6240 - val_loss: 1.2176 - val_accuracy: 0.4884\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 6s 106ms/step - loss: 0.8220 - accuracy: 0.6420 - val_loss: 0.9329 - val_accuracy: 0.6233\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 6s 107ms/step - loss: 0.7633 - accuracy: 0.6903 - val_loss: 1.0785 - val_accuracy: 0.5535\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 6s 107ms/step - loss: 0.7097 - accuracy: 0.7258 - val_loss: 0.9262 - val_accuracy: 0.6605\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.7277 - accuracy: 0.7189 - val_loss: 0.7723 - val_accuracy: 0.6953\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.5616 - accuracy: 0.7695 - val_loss: 0.6133 - val_accuracy: 0.7884\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 6s 108ms/step - loss: 0.4948 - accuracy: 0.7998 - val_loss: 0.6127 - val_accuracy: 0.7907\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.4414 - accuracy: 0.8353 - val_loss: 0.8816 - val_accuracy: 0.6465\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 6s 107ms/step - loss: 0.3715 - accuracy: 0.8644 - val_loss: 0.6298 - val_accuracy: 0.7233\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.3102 - accuracy: 0.8871 - val_loss: 0.4238 - val_accuracy: 0.8488\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 6s 102ms/step - loss: 0.2902 - accuracy: 0.8958 - val_loss: 0.4641 - val_accuracy: 0.8256\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.2114 - accuracy: 0.9185 - val_loss: 0.3704 - val_accuracy: 0.8930\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 6s 102ms/step - loss: 0.2306 - accuracy: 0.9267 - val_loss: 0.9907 - val_accuracy: 0.7093\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.1861 - accuracy: 0.9360 - val_loss: 0.3674 - val_accuracy: 0.8674\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.2336 - accuracy: 0.9255 - val_loss: 0.2111 - val_accuracy: 0.9279\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.1807 - accuracy: 0.9360 - val_loss: 0.3324 - val_accuracy: 0.8698\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.1305 - accuracy: 0.9517 - val_loss: 0.2603 - val_accuracy: 0.9395\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.2009 - accuracy: 0.9237 - val_loss: 0.5041 - val_accuracy: 0.8395\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 5s 99ms/step - loss: 0.1488 - accuracy: 0.9529 - val_loss: 0.3191 - val_accuracy: 0.9070\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.1660 - accuracy: 0.9464 - val_loss: 0.3103 - val_accuracy: 0.8837\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.1116 - accuracy: 0.9645 - val_loss: 0.2936 - val_accuracy: 0.9349\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 6s 102ms/step - loss: 0.0949 - accuracy: 0.9738 - val_loss: 0.3057 - val_accuracy: 0.9209\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.0725 - accuracy: 0.9761 - val_loss: 0.2797 - val_accuracy: 0.9140\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.0967 - accuracy: 0.9697 - val_loss: 0.3601 - val_accuracy: 0.9140\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.0686 - accuracy: 0.9726 - val_loss: 0.2662 - val_accuracy: 0.9326\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.0805 - accuracy: 0.9761 - val_loss: 0.9882 - val_accuracy: 0.8349\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 6s 102ms/step - loss: 0.0422 - accuracy: 0.9895 - val_loss: 0.2791 - val_accuracy: 0.9349\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.0394 - accuracy: 0.9831 - val_loss: 0.1631 - val_accuracy: 0.9628\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.0388 - accuracy: 0.9924 - val_loss: 0.2102 - val_accuracy: 0.9488\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.0429 - accuracy: 0.9872 - val_loss: 0.2544 - val_accuracy: 0.9349\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.1062 - accuracy: 0.9686 - val_loss: 0.2497 - val_accuracy: 0.9442\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.0407 - accuracy: 0.9854 - val_loss: 0.1242 - val_accuracy: 0.9744\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.0299 - accuracy: 0.9913 - val_loss: 0.1934 - val_accuracy: 0.9465\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.0272 - accuracy: 0.9919 - val_loss: 0.1707 - val_accuracy: 0.9628\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.1081 - accuracy: 0.9767 - val_loss: 0.1558 - val_accuracy: 0.9512\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 6s 102ms/step - loss: 0.2329 - accuracy: 0.9395 - val_loss: 0.4053 - val_accuracy: 0.8651\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.1841 - accuracy: 0.9523 - val_loss: 0.2576 - val_accuracy: 0.9512\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.1367 - accuracy: 0.9633 - val_loss: 0.2017 - val_accuracy: 0.9372\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.0901 - accuracy: 0.9726 - val_loss: 0.3902 - val_accuracy: 0.9116\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 6s 110ms/step - loss: 0.1185 - accuracy: 0.9610 - val_loss: 0.2860 - val_accuracy: 0.9233\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.0736 - accuracy: 0.9808 - val_loss: 0.1671 - val_accuracy: 0.9488\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.0473 - accuracy: 0.9854 - val_loss: 0.3315 - val_accuracy: 0.8953\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.0457 - accuracy: 0.9837 - val_loss: 0.1603 - val_accuracy: 0.9512\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.1766 - val_accuracy: 0.9651\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 5s 99ms/step - loss: 0.0262 - accuracy: 0.9919 - val_loss: 0.2038 - val_accuracy: 0.9581\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.0225 - accuracy: 0.9913 - val_loss: 0.1902 - val_accuracy: 0.9628\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 5s 99ms/step - loss: 0.0162 - accuracy: 0.9930 - val_loss: 0.1312 - val_accuracy: 0.9721\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 5s 99ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.1643 - val_accuracy: 0.9721\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.0055 - accuracy: 0.9977 - val_loss: 0.1810 - val_accuracy: 0.9605\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 5s 99ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1760 - val_accuracy: 0.9674\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 5s 99ms/step - loss: 0.0072 - accuracy: 0.9959 - val_loss: 0.1915 - val_accuracy: 0.9558\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.0102 - accuracy: 0.9959 - val_loss: 0.1372 - val_accuracy: 0.9698\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 5s 99ms/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.1477 - val_accuracy: 0.9698\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 5s 99ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.1698 - val_accuracy: 0.9651\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 6s 102ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1907 - val_accuracy: 0.9721\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.6422 - val_accuracy: 0.9349\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 5s 99ms/step - loss: 0.0287 - accuracy: 0.9953 - val_loss: 0.1146 - val_accuracy: 0.9767\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.1320 - val_accuracy: 0.9698\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 5s 99ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.2001 - val_accuracy: 0.9419\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 0.6420 - val_accuracy: 0.8837\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.2967 - val_accuracy: 0.9488\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.3221 - val_accuracy: 0.9419\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 5s 99ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.7378 - val_accuracy: 0.8930\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.0329 - accuracy: 0.9901 - val_loss: 0.2249 - val_accuracy: 0.9512\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 5s 99ms/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 0.1193 - val_accuracy: 0.9651\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.0489 - accuracy: 0.9895 - val_loss: 0.1950 - val_accuracy: 0.9535\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.0543 - accuracy: 0.9825 - val_loss: 0.1374 - val_accuracy: 0.9721\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 6s 105ms/step - loss: 0.0440 - accuracy: 0.9872 - val_loss: 0.2130 - val_accuracy: 0.9512\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.0658 - accuracy: 0.9866 - val_loss: 0.3026 - val_accuracy: 0.9372\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.0581 - accuracy: 0.9820 - val_loss: 0.4393 - val_accuracy: 0.9488\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.1510 - accuracy: 0.9773 - val_loss: 0.4304 - val_accuracy: 0.8814\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.1147 - accuracy: 0.9721 - val_loss: 0.2869 - val_accuracy: 0.9116\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 6s 102ms/step - loss: 0.0693 - accuracy: 0.9808 - val_loss: 0.3347 - val_accuracy: 0.9326\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.0527 - accuracy: 0.9895 - val_loss: 0.2750 - val_accuracy: 0.9442\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.0479 - accuracy: 0.9889 - val_loss: 0.2414 - val_accuracy: 0.9488\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.1616 - val_accuracy: 0.9605\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.2412 - val_accuracy: 0.9605\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.0215 - accuracy: 0.9924 - val_loss: 0.1792 - val_accuracy: 0.9628\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.0092 - accuracy: 0.9953 - val_loss: 0.2676 - val_accuracy: 0.9512\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 5s 100ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.1635 - val_accuracy: 0.9674\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.0148 - accuracy: 0.9988 - val_loss: 0.3802 - val_accuracy: 0.9419\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.0280 - accuracy: 0.9971 - val_loss: 0.5202 - val_accuracy: 0.9419\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.3185 - val_accuracy: 0.9605\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.0306 - accuracy: 0.9919 - val_loss: 0.2406 - val_accuracy: 0.9465\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 5s 102ms/step - loss: 0.0310 - accuracy: 0.9901 - val_loss: 0.4982 - val_accuracy: 0.9023\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.0173 - accuracy: 0.9959 - val_loss: 0.3623 - val_accuracy: 0.9302\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 6s 106ms/step - loss: 0.0711 - accuracy: 0.9878 - val_loss: 0.2747 - val_accuracy: 0.9535\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.0217 - accuracy: 0.9924 - val_loss: 0.2867 - val_accuracy: 0.9581\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.0366 - accuracy: 0.9919 - val_loss: 0.3032 - val_accuracy: 0.9488\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 6s 104ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.1713 - val_accuracy: 0.9698\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 6s 102ms/step - loss: 0.0208 - accuracy: 0.9948 - val_loss: 0.2587 - val_accuracy: 0.9651\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 5s 101ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.2277 - val_accuracy: 0.9581\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 6s 103ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.4313 - val_accuracy: 0.9465\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4313 - accuracy: 0.9465\n",
      "Test Accuracy: 0.9465116262435913\n",
      "Test loss: 0.431254118680954\n",
      "14/14 [==============================] - 0s 30ms/step\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "       38s&ws_dot38_caliber       0.99      0.95      0.97       102\n",
      "ruger_ar_556_dot223_caliber       0.97      0.93      0.94       120\n",
      "     remington_870_12_gauge       0.99      0.88      0.93        78\n",
      "       glock_17_9mm_caliber       0.88      1.00      0.94       130\n",
      "\n",
      "                   accuracy                           0.95       430\n",
      "                  macro avg       0.96      0.94      0.95       430\n",
      "               weighted avg       0.95      0.95      0.95       430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "def read_data(folder_path, fft_size=1024, hop_length=None, win_length=None):\n",
    "    labels = []\n",
    "    spectrograms = []\n",
    "\n",
    "    for label in os.listdir(folder_path):\n",
    "        subfolder_path = os.path.join(folder_path, label)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            for file in os.listdir(subfolder_path):\n",
    "                file_path = os.path.join(subfolder_path, file)\n",
    "                if file_path.endswith('.wav'):\n",
    "                    y, sr = librosa.load(file_path)\n",
    "                    spectrogram = librosa.stft(y, n_fft=fft_size, hop_length=hop_length, win_length=win_length)\n",
    "                    spectrogram = np.abs(spectrogram)\n",
    "                    spectrograms.append(spectrogram)\n",
    "                    labels.append(label)\n",
    "\n",
    "    return spectrograms, labels\n",
    "\n",
    "\n",
    "def pad2d(a, desired_size):\n",
    "    rows, cols = a.shape\n",
    "    padded_a = np.zeros((desired_size, desired_size))\n",
    "    rows_to_copy = min(rows, desired_size)\n",
    "    cols_to_copy = min(cols, desired_size)\n",
    "    padded_a[:rows_to_copy, :cols_to_copy] = a[:rows_to_copy, :cols_to_copy]\n",
    "    return padded_a\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))   # conv2d 32 3x3\n",
    "    model.add(MaxPooling2D((2, 2))) # maxpool 2x2\n",
    "    model.add(BatchNormalization()) # batchnorm\n",
    "    model.add(Conv2D(64, (4, 4), activation='relu'))    # changed to 4x4\n",
    "    model.add(MaxPooling2D((2, 2))) # maxpool 2x2\n",
    "    model.add(BatchNormalization()) # batchnorm\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))   # conv2d 128 3x3\n",
    "    model.add(MaxPooling2D((2, 2))) # maxpool 2x2\n",
    "    model.add(BatchNormalization()) # batchnorm\n",
    "    model.add(Conv2D(256, (5, 5), activation='relu'))   # newly added conv2d 256 5x5\n",
    "    model.add(MaxPooling2D((2, 2))) # maxpool 2x2\n",
    "    model.add(BatchNormalization()) # batchnorm\n",
    "    model.add(Flatten())    # flatten the model\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))    # dense 128\n",
    "    model.add(Dropout(0.5)) # dropout 0.5\n",
    "    model.add(Dense(num_classes, activation='softmax')) # dense for output\n",
    "    return model\n",
    "\n",
    "folder_path = 'Gun Shot dataset/edge-collected-gunshot-audio'\n",
    "\n",
    "spectrograms, labels = read_data(folder_path, fft_size=2048, hop_length=512, win_length=2048)   # added fft size hop length and win length as extra parameters\n",
    "\n",
    "\n",
    "\n",
    "desired_spectrogram_size = 128\n",
    "spectrograms = np.array([pad2d(s, desired_spectrogram_size) for s in spectrograms]) # pad\n",
    "spectrograms = np.expand_dims(spectrograms, axis=-1)    # expand dims\n",
    "print(spectrograms.shape)   # print shape\n",
    "label_dict = {label: i for i, label in enumerate(set(labels))}\n",
    "y = np.array([label_dict[label] for label in labels])\n",
    "y = to_categorical(y)  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(spectrograms, y, test_size=0.2, random_state=42)    # train test split\n",
    "\n",
    "input_shape = X_train[0].shape\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "model = create_cnn_model(input_shape, num_classes)  # create model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # compile model\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))   # train model\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = model.evaluate(X_test, y_test)   # evaluate model\n",
    "print(f\"Test Accuracy: {cnn_test_accuracy}\")    # print test accuracy\n",
    "print(f\"Test loss: {cnn_test_loss}\")    # print test loss\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "cnn_report = classification_report(y_true_classes, y_pred_classes, target_names=label_dict.keys())  # classification report to show precision, recall, and f1 score\n",
    "\n",
    "print(cnn_report)   # print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this model I added an extra 256 5x5 layer and changed the size of the filters in the second layer to 4x4\n",
    "# this helped improve the model overall\n",
    "# I also attempted to add multiple dense layers, dropout layers, and more conv layers\n",
    "# The added complexity did not help however and only hurt the accuracy, so I trimmed it down to what is seen above\n",
    "\n",
    "# I tried cutting down on epochs to avoid overfitting and help on runtime, but this caused the accuracy to drop\n",
    "# this means that there is not much overfitting in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM CNN\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "       38s&ws_dot38_caliber       0.98      0.99      0.99       102\n",
      "ruger_ar_556_dot223_caliber       0.98      0.97      0.97       120\n",
      "     remington_870_12_gauge       0.99      0.91      0.95        78\n",
      "       glock_17_9mm_caliber       0.94      0.99      0.97       130\n",
      "\n",
      "                   accuracy                           0.97       430\n",
      "                  macro avg       0.97      0.96      0.97       430\n",
      "               weighted avg       0.97      0.97      0.97       430\n",
      "\n",
      "LSTM\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "       38s&ws_dot38_caliber       0.88      0.98      0.93       102\n",
      "ruger_ar_556_dot223_caliber       0.94      0.93      0.93       120\n",
      "     remington_870_12_gauge       0.93      0.86      0.89        78\n",
      "       glock_17_9mm_caliber       0.92      0.90      0.91       130\n",
      "\n",
      "                   accuracy                           0.92       430\n",
      "                  macro avg       0.92      0.92      0.92       430\n",
      "               weighted avg       0.92      0.92      0.92       430\n",
      "\n",
      "CNN\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "       38s&ws_dot38_caliber       0.99      0.95      0.97       102\n",
      "ruger_ar_556_dot223_caliber       0.97      0.93      0.94       120\n",
      "     remington_870_12_gauge       0.99      0.88      0.93        78\n",
      "       glock_17_9mm_caliber       0.88      1.00      0.94       130\n",
      "\n",
      "                   accuracy                           0.95       430\n",
      "                  macro avg       0.96      0.94      0.95       430\n",
      "               weighted avg       0.95      0.95      0.95       430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"LSTM CNN\")\n",
    "print(lstm_cnn_report)\n",
    "print(\"LSTM\")\n",
    "print(lstm_report)\n",
    "print(\"CNN\")\n",
    "print(cnn_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall of the three models I implemented between LSTM, CNN, and CNN LSTM, the CNN+LSTM model performed the best\n",
    "# it had the highest accuracy, f1 score, and recall with the exception of the Glock 17 recall which was better in the CNN model\n",
    "# as well as the 38 S&W precision which was better in the CNN model\n",
    "\n",
    "# The CNN+LSTM model performed the best overall most likely due to the fact that it combines the two models\n",
    "# this allows it to take advantage of the strengths of both models and minimize the weaknesses\n",
    "# the CNN model is good at extracting features from the data, while the LSTM model is good at processing sequences\n",
    "# this means that the CNN+LSTM model is good at extracting features from the data and processing them in sequence\n",
    "# it had a overall accuracy of 97%, higher than the CNN model by 2% and the LSTM model by 5%\n",
    "\n",
    "# the LSTM model performed the worst overall, this is most likely due to the fact that it is not as good at extracting features from the data\n",
    "# this is because it is not meant for image data, but rather for sequence data\n",
    "\n",
    "# I am surpised that the CNN model performed better than the combined model in the case of the Glock 17 recall and the 38 S&W precision\n",
    "# this may just be the result of the final run of the model and may not be consistent\n",
    "# though I am not surprised that the CNN model performed better than the LSTM model overall\n",
    "# For the Glock 17 recall, I am very surprised that it reached 1.00, this may be a one off event\n",
    "# but this means that out of the times that the model predicted that it was NOT a Glock 17, it was never wrong \n",
    "\n",
    "# The F1 score for the Remington 870 was the lowest in all three models, most likely due to the fact that it has the fewest samples in the dataset\n",
    "# this means that the model has less data to learn from and is less accurate when predicting the Remington 870\n",
    "# However the 38 S&W had the highest F1 score in all three models, however it did not have the most samples\n",
    "# this may be due to it producting the most distinct sound out of these guns, and thus being easier to identify\n",
    "\n",
    "# In conclusion the best model for this task is the CNN+LSTM model, as it combines the strengths of both models\n",
    "# It was able to achieve the highest average in accuracy, precision, recall, and F1 score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
